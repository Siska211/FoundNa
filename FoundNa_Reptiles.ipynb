{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-uP7AKxmPGe"
      },
      "source": [
        "**IMPORT LIBARARY**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GCwIG-3kI_h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten,Input\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import os\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1GYBdeRmYUD"
      },
      "source": [
        "**DOWNLOAD FILE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSesuQytkW2z",
        "outputId": "527bb01d-74dc-41a7-fce6-046addf98557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-11 03:32:54--  https://github.com/Siska211/FoundNa/releases/download/v1.0.2/Dataset_Reptiles.zip\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/637553860/add4df2b-b204-4616-96e1-487eb6ed49b0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230611%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230611T033254Z&X-Amz-Expires=300&X-Amz-Signature=f9d08e08c3918d9ff31581fd1cdee0db7f6c3fadf87dc88f0a11d3cc88dd4279&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=637553860&response-content-disposition=attachment%3B%20filename%3DDataset_Reptiles.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-06-11 03:32:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/637553860/add4df2b-b204-4616-96e1-487eb6ed49b0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230611%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230611T033254Z&X-Amz-Expires=300&X-Amz-Signature=f9d08e08c3918d9ff31581fd1cdee0db7f6c3fadf87dc88f0a11d3cc88dd4279&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=637553860&response-content-disposition=attachment%3B%20filename%3DDataset_Reptiles.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238568334 (228M) [application/octet-stream]\n",
            "Saving to: ‘Dataset_Reptiles.zip.2’\n",
            "\n",
            "Dataset_Reptiles.zi 100%[===================>] 227.52M  69.1MB/s    in 3.3s    \n",
            "\n",
            "2023-06-11 03:32:58 (69.4 MB/s) - ‘Dataset_Reptiles.zip.2’ saved [238568334/238568334]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Download File Dalam Bentuk Zip\n",
        "!wget --no-check-certificate \\\n",
        "https://github.com/Siska211/FoundNa/releases/download/v1.0.2/Dataset_Reptiles.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kglz9eSdkaGH"
      },
      "outputs": [],
      "source": [
        "import zipfile,os\n",
        "zipfile = zipfile.ZipFile(\"/content/Dataset_Reptiles.zip\", 'r')\n",
        "zipfile.extractall(\"/content/Dataset_Reptiles\")\n",
        "zipfile.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkmgXuTqmkCQ"
      },
      "source": [
        "**DISPLAY FILE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y6s2tFjkc0H",
        "outputId": "711ba801-da4a-48e1-8e47-84fe7b1971b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          filepaths    labels\n",
            "0          /content/Dataset_Reptiles/Reptiles/Buaya  Reptiles\n",
            "1  /content/Dataset_Reptiles/Reptiles/Biawak Komodo  Reptiles\n",
            "2   /content/Dataset_Reptiles/Reptiles/Monster Gila  Reptiles\n",
            "3         /content/Dataset_Reptiles/Reptiles/Iguana  Reptiles\n",
            "4         /content/Dataset_Reptiles/Reptiles/Gavial  Reptiles\n",
            "Reptiles    6\n",
            "Name: labels, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "sdir=r'/content/Dataset_Reptiles'\n",
        "\n",
        "filepaths=[]\n",
        "labels=[]\n",
        "classlist=os.listdir(sdir)\n",
        "for klass in classlist:\n",
        "    classpath=os.path.join(sdir,klass)\n",
        "    if os.path.isdir(classpath):\n",
        "        flist=os.listdir(classpath)\n",
        "        for f in flist:\n",
        "            fpath=os.path.join(classpath,f)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(klass)                   \n",
        "Fseries= pd.Series(filepaths, name='filepaths')\n",
        "Lseries=pd.Series(labels, name='labels')    \n",
        "df=pd.concat([Fseries, Lseries], axis=1)\n",
        "print (df.head())\n",
        "print (df['labels'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqE8Mmjbmq79"
      },
      "source": [
        "**SPLIT DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hqcRcl-kj9E",
        "outputId": "84d289c4-5956-401d-93b3-0195768204a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_df length:  4   test_df length:  1   valid_df length:  1\n"
          ]
        }
      ],
      "source": [
        "train_split=.8\n",
        "test_split=.1\n",
        "dummy_split=test_split/(1-train_split)\n",
        "train_df, dummy_df=train_test_split(df, train_size=train_split, shuffle=True, random_state=300)\n",
        "test_df, valid_df=train_test_split(dummy_df, train_size=dummy_split, shuffle=True, random_state=300)\n",
        "print ('train_df length: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTX8zTHxmvFR"
      },
      "source": [
        "**IMAGE AUGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZl_WSrokk2h",
        "outputId": "bb2000fc-8ccd-439f-c5cf-601a5006a44d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test batch size:  1   test steps:  1\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "Found 0 validated image filenames belonging to 0 classes.\n",
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1137: UserWarning: Found 4 invalid image filename(s) in x_col=\"filepaths\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filepaths\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filepaths\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "height=150\n",
        "width=150\n",
        "channels=3\n",
        "batch_size=64\n",
        "\n",
        "img_shape=(height, width, channels)\n",
        "img_size=(height, width)\n",
        "length=len(test_df)\n",
        "test_batch_size=sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
        "test_steps=int(length/test_batch_size)\n",
        "print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps)\n",
        "\n",
        "gen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    )\n",
        "train_gen=gen.flow_from_dataframe( train_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
        "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "\n",
        "validgen=ImageDataGenerator(rescale=1./255)\n",
        "valid_gen=validgen.flow_from_dataframe( valid_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
        "                                    color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
        "\n",
        "testgen=ImageDataGenerator(rescale=1./255)\n",
        "test_gen=testgen.flow_from_dataframe( test_df, x_col='filepaths', y_col='labels', target_size=img_size, class_mode='categorical',\n",
        "                                    color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
        "\n",
        "classes=list(train_gen.class_indices.keys())\n",
        "print (classes)\n",
        "class_count=len(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GNhvDWDm4zu"
      },
      "source": [
        "**SHOW THE SAMPLE IMAGE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWDcO_dFkoh1"
      },
      "outputs": [],
      "source": [
        "def show_image_samples(gen):\n",
        "    test_dict=test_gen.class_indices\n",
        "    classes=list(test_dict.keys())    \n",
        "    images,labels=next(gen) \n",
        "    plt.figure(figsize=(20, 20))\n",
        "    length=len(labels)\n",
        "    if length<25: \n",
        "        r=length\n",
        "    else:\n",
        "        r=25\n",
        "    for i in range(r):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        image=images[i]\n",
        "        plt.imshow(image)\n",
        "        index=np.argmax(labels[i])\n",
        "        class_name=classes[index]\n",
        "        plt.title(class_name, color='blue', fontsize=16)\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "6yMofrD6krr0",
        "outputId": "02f78912-be64-4c39-b99a-bd93cae4d3d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x2000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "show_image_samples(train_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGdjYQg6m-kp"
      },
      "source": [
        "**CREATE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UujhABKkuBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680fe239-204b-41ab-b33c-bc0731382492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building model with <keras.engine.functional.Functional object at 0x7f98491c44c0>\n"
          ]
        }
      ],
      "source": [
        "base_model=tf.keras.applications.MobileNetV2(include_top=False, weights=\"imagenet\",input_tensor=Input(shape=(150,150,3)))\n",
        "\n",
        "model_name='model_foundna'\n",
        "print(\"Building model with\", base_model)\n",
        "model = tf.keras.Sequential([\n",
        "            base_model,\n",
        "            tf.keras.layers.Conv2D(filters=32, padding='same', kernel_size=3, activation='relu', strides=1),\n",
        "            tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "            tf.keras.layers.Conv2D(filters=64, padding='same', kernel_size=3, activation='relu', strides=1),\n",
        "            tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
        "            tf.keras.layers.Dropout(rate=0.5),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(100, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.0001), loss='categorical_crossentropy', metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lRjjwZZxk7RS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ab1a5d-f332-4db5-ea8d-8559e1175d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 5, 5, 1280)       2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 5, 5, 32)          368672    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 2, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 2, 2, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 1, 1, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1, 1, 64)          0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               6500      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,651,652\n",
            "Trainable params: 2,617,540\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJG3zL_jnCdK"
      },
      "source": [
        "**TRAINING MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "B99ESut8k-qw",
        "outputId": "48bd42bd-7a3f-4ea6-9486-68ed186dc867"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6858296da609>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                 \u001b[0;34m\"Asked to retrieve element {idx}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;34m\"but the Sequence \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
          ]
        }
      ],
      "source": [
        "history=model.fit(x=train_gen, epochs=20, validation_data=valid_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzeCBidpnGve"
      },
      "source": [
        "**VISUALIZATION MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajtVHZszk_Kh"
      },
      "outputs": [],
      "source": [
        "def tr_plot(tr_data, start_epoch):\n",
        "    #Plot the training and validation data\n",
        "    tacc=tr_data.history['accuracy']\n",
        "    tloss=tr_data.history['loss']\n",
        "    vacc=tr_data.history['val_accuracy']\n",
        "    vloss=tr_data.history['val_loss']\n",
        "    Epoch_count=len(tacc)+ start_epoch\n",
        "    Epochs=[]\n",
        "    for i in range (start_epoch ,Epoch_count):\n",
        "        Epochs.append(i+1)   \n",
        "    index_loss=np.argmin(vloss)\n",
        "    val_lowest=vloss[index_loss]\n",
        "    index_acc=np.argmax(vacc)\n",
        "    acc_highest=vacc[index_acc]\n",
        "    plt.style.use('fivethirtyeight')\n",
        "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
        "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
        "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
        "    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
        "    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
        "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].set_xlabel('Epochs')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
        "    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
        "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
        "    axes[1].set_title('Training and Validation Accuracy')\n",
        "    axes[1].set_xlabel('Epochs')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].legend()\n",
        "    plt.tight_layout\n",
        "    #plt.style.use('fivethirtyeight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LNfTfwZlEB7"
      },
      "outputs": [],
      "source": [
        "def print_info( test_gen, preds, print_code, save_dir, subject ):\n",
        "    class_dict=test_gen.class_indices\n",
        "    labels= test_gen.labels\n",
        "    file_names= test_gen.filenames \n",
        "    error_list=[]\n",
        "    true_class=[]\n",
        "    pred_class=[]\n",
        "    prob_list=[]\n",
        "    new_dict={}\n",
        "    error_indices=[]\n",
        "    y_pred=[]\n",
        "    for key,value in class_dict.items():\n",
        "        new_dict[value]=key             # dictionary {integer of class number: string of class name}\n",
        "    # store new_dict as a text fine in the save_dir\n",
        "    classes=list(new_dict.values())     # list of string of class names\n",
        "    dict_as_text=str(new_dict)\n",
        "    dict_name= subject + '-' +str(len(classes)) +'.txt'  \n",
        "    dict_path=os.path.join(save_dir,dict_name)    \n",
        "    with open(dict_path, 'w') as x_file:\n",
        "        x_file.write(dict_as_text)    \n",
        "    errors=0      \n",
        "    for i, p in enumerate(preds):\n",
        "        pred_index=np.argmax(p)        \n",
        "        true_index=labels[i]  # labels are integer values\n",
        "        if pred_index != true_index: # a misclassification has occurred\n",
        "            error_list.append(file_names[i])\n",
        "            true_class.append(new_dict[true_index])\n",
        "            pred_class.append(new_dict[pred_index])\n",
        "            prob_list.append(p[pred_index])\n",
        "            error_indices.append(true_index)            \n",
        "            errors=errors + 1\n",
        "        y_pred.append(pred_index)    \n",
        "    if print_code !=0:\n",
        "        if errors>0:\n",
        "            if print_code>errors:\n",
        "                r=errors\n",
        "            else:\n",
        "                r=print_code           \n",
        "            msg='{0:^28s}{1:^28s}{2:^28s}{3:^16s}'.format('Filename', 'Predicted Class' , 'True Class', 'Probability')\n",
        "            print_in_color(msg, (0,255,0),(55,65,80))\n",
        "            for i in range(r):                \n",
        "                split1=os.path.split(error_list[i])                \n",
        "                split2=os.path.split(split1[0])                \n",
        "                fname=split2[1] + '/' + split1[1]\n",
        "                msg='{0:^28s}{1:^28s}{2:^28s}{3:4s}{4:^6.4f}'.format(fname, pred_class[i],true_class[i], ' ', prob_list[i])\n",
        "                print_in_color(msg, (255,255,255), (55,65,60))\n",
        "                #print(error_list[i]  , pred_class[i], true_class[i], prob_list[i])               \n",
        "        else:\n",
        "            msg='With accuracy of 100 % there are no errors to print'\n",
        "            print_in_color(msg, (0,255,0),(55,65,80))\n",
        "    if errors>0:\n",
        "        plot_bar=[]\n",
        "        plot_class=[]\n",
        "        for  key, value in new_dict.items():        \n",
        "            count=error_indices.count(key) \n",
        "            if count!=0:\n",
        "                plot_bar.append(count) # list containg how many times a class c had an error\n",
        "                plot_class.append(value)   # stores the class \n",
        "        fig=plt.figure()\n",
        "        fig.set_figheight(len(plot_class)/3)\n",
        "        fig.set_figwidth(10)\n",
        "        plt.style.use('fivethirtyeight')\n",
        "        for i in range(0, len(plot_class)):\n",
        "            c=plot_class[i]\n",
        "            x=plot_bar[i]\n",
        "            plt.barh(c, x, )\n",
        "            plt.title( ' Errors by Class on Test Set')\n",
        "    y_true= np.array(labels)        \n",
        "    y_pred=np.array(y_pred)\n",
        "    if len(classes)<= 30:\n",
        "        # create a confusion matrix \n",
        "        cm = confusion_matrix(y_true, y_pred )        \n",
        "        length=len(classes)\n",
        "        if length<8:\n",
        "            fig_width=8\n",
        "            fig_height=8\n",
        "        else:\n",
        "            fig_width= int(length * .5)\n",
        "            fig_height= int(length * .5)\n",
        "        plt.figure(figsize=(fig_width, fig_height))\n",
        "        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
        "        plt.xticks(np.arange(length)+.5, classes, rotation= 90)\n",
        "        plt.yticks(np.arange(length)+.5, classes, rotation=0)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"Actual\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "    clr = classification_report(y_true, y_pred, target_names=classes)\n",
        "    print(\"Classification Report:\\n----------------------\\n\", clr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLTlWzlPlKWp"
      },
      "outputs": [],
      "source": [
        "tr_plot(history,0)\n",
        "save_dir=r'./'\n",
        "subject='pest'\n",
        "acc=model.evaluate( test_gen, batch_size=test_batch_size, verbose=1, steps=test_steps, return_dict=False)[1]*100\n",
        "msg=f'accuracy on the test set is {acc:5.2f} %'\n",
        "save_id=str (model_name +  '-' + subject +'-'+ str(acc)[:str(acc).rfind('.')+3] + '.h5')\n",
        "save_loc=os.path.join(save_dir, save_id)\n",
        "model.save(save_loc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7MMner8lNI8"
      },
      "outputs": [],
      "source": [
        "print_code=0\n",
        "preds=model.predict(test_gen) \n",
        "print_info( test_gen, preds, print_code, save_dir, subject ) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSJADTJunUA8"
      },
      "source": [
        "**TESTING MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3gYpoU6llWKP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "\n",
        "# Load the image\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  path = fn \n",
        "  img = tf.keras.utils.load_img(path, target_size =(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = tf.keras.utils.img_to_array(img)\n",
        "  n_image = x / 255.0 \n",
        "  y = np.expand_dims(n_image, axis=0)\n",
        "  images = np.vstack([y])\n",
        "\n",
        "# Load the trained model\n",
        "  model = tf.keras.models.load_model('model_foundna-pest-72.22.h5')\n",
        "\n",
        "# Make predictions on the input data\n",
        "  predictions = model.predict(images)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "  class_labels = ['ABBOTTS BABBLER','ABBOTTS BOOBY','ABYSSINIAN GROUND HORNBILL','AFRICAN CROWNED CRANE','AFRICAN EMERALD CUCKOO']\n",
        "  predicted_classes = np.argmax(predictions, axis=1)\n",
        "  predicted_labels = [class_labels[prediction] for prediction in predicted_classes]\n",
        "\n",
        "# Print the predicted labels\n",
        "  print(predicted_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzwvSn8YnYk0"
      },
      "source": [
        "**CONVERT MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBIA_bDQlZa1"
      },
      "outputs": [],
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCL4TdE2gPDs"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Mendownload file ZIP ke lokal\n",
        "files.download('model_foundna-pest-72.22.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4Yh1EtNgT0z"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Mendownload file ZIP ke lokal\n",
        "files.download('model.tflite')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}