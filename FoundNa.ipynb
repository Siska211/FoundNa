{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORT LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download File Zip\n",
    "!wget -q -P /content/ https://github.com/Siska211/FoundNa/releases/download/v1.0.1/Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "file = \"./Dataset_FoundNa.zip\"\n",
    "zipfile = zipfile.ZipFile(file, 'r')\n",
    "zipfile.extractall(\"/FoundNa\")\n",
    "zipfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           filePath    labels\n",
      "0  /FoundNa\\antelope\\02f4b3be2d.jpg  antelope\n",
      "1  /FoundNa\\antelope\\03d7fc0888.jpg  antelope\n",
      "2  /FoundNa\\antelope\\058fa9a60f.jpg  antelope\n",
      "3  /FoundNa\\antelope\\0a37838e99.jpg  antelope\n",
      "4  /FoundNa\\antelope\\0b1a3af197.jpg  antelope\n",
      "labels\n",
      "Dataset               13714\n",
      "Dolphin                 200\n",
      "Lobster                 200\n",
      "Otter                   200\n",
      "Octopus                 200\n",
      "                      ...  \n",
      "fox-resize-300            1\n",
      "cheetah-resize-224        1\n",
      "fox-resize-512            1\n",
      "cheetah-resize-512        1\n",
      "cheetah-resize-300        1\n",
      "Name: count, Length: 129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "base_dir = \"/FoundNa\"\n",
    "\n",
    "filePath=[]\n",
    "labels=[]\n",
    "class_list=os.listdir(base_dir)\n",
    "for Class in class_list:\n",
    "    class_path=os.path.join(base_dir,Class)\n",
    "    if os.path.isdir(class_path):\n",
    "        flist=os.listdir(class_path)\n",
    "        for f in flist:\n",
    "            fpath=os.path.join(class_path,f)\n",
    "            filePath.append(fpath)\n",
    "            labels.append(Class)                   \n",
    "Fseries= pd.Series(filePath, name='filePath')\n",
    "Lseries=pd.Series(labels, name='labels')    \n",
    "df=pd.concat([Fseries, Lseries], axis=1)\n",
    "print (df.head())\n",
    "print (df['labels'].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "train_size=1.0000000000000002 should be either positive and smaller than the number of samples 2743 or a float in the (0, 1) range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m dummy_split\u001b[39m=\u001b[39mval_split\u001b[39m/\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mtrain_split)\n\u001b[0;32m      4\u001b[0m train_df, dummy_df\u001b[39m=\u001b[39mtrain_test_split(df, train_size\u001b[39m=\u001b[39mtrain_split, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m123\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m val_df\u001b[39m=\u001b[39mtrain_test_split(dummy_df, train_size\u001b[39m=\u001b[39;49mdummy_split, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, random_state\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mtrain_df length: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(train_df), \u001b[39m'\u001b[39m\u001b[39m  val_df length: \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(val_df))\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Python3.11.3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2559\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m-> 2562\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[0;32m   2563\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39;49m\u001b[39m0.25\u001b[39;49m\n\u001b[0;32m   2564\u001b[0m )\n\u001b[0;32m   2566\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     \u001b[39mif\u001b[39;00m stratify \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\Python3.11.3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2193\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2181\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtest_size=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m should be either positive and smaller\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2183\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m than the number of samples \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m or a float in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2184\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(0, 1) range\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(test_size, n_samples)\n\u001b[0;32m   2185\u001b[0m     )\n\u001b[0;32m   2187\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2188\u001b[0m     train_size_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2189\u001b[0m     \u001b[39mand\u001b[39;00m (train_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m n_samples \u001b[39mor\u001b[39;00m train_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m   2190\u001b[0m     \u001b[39mor\u001b[39;00m train_size_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2191\u001b[0m     \u001b[39mand\u001b[39;00m (train_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m train_size \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m   2192\u001b[0m ):\n\u001b[1;32m-> 2193\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2194\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrain_size=\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m should be either positive and smaller\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2195\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m than the number of samples \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m or a float in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2196\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(0, 1) range\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(train_size, n_samples)\n\u001b[0;32m   2197\u001b[0m     )\n\u001b[0;32m   2199\u001b[0m \u001b[39mif\u001b[39;00m train_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m train_size_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m   2200\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid value for train_size: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(train_size))\n",
      "\u001b[1;31mValueError\u001b[0m: train_size=1.0000000000000002 should be either positive and smaller than the number of samples 2743 or a float in the (0, 1) range"
     ]
    }
   ],
   "source": [
    "train_split=.8\n",
    "val_split=.2\n",
    "dummy_split=val_split/(1-train_split)\n",
    "train_df, dummy_df=train_test_split(df, train_size=train_split, shuffle=True, random_state=123)\n",
    "val_df=train_test_split(dummy_df, train_size=dummy_split, shuffle=True, random_state=123)\n",
    "print ('train_df length: ', len(train_df), '  val_df length: ', len(val_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Augmentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATE MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
